{% set name = "onnxruntime" %}
{% set version = "1.11.1" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  - url: https://github.com/microsoft/onnxruntime/archive/refs/tags/v{{ version }}.tar.gz
    sha256: 307ba492dc6a35992ca561fa1c90ad919ed6bd40adef578a07725b5e88ccf633
    patches:
      - 0001-Fix-for-tests-failures-with-cuda-build-type.patch       #[build_type=='cuda']
      - 0001-Fix-for-NVCC-error.patch                                #[build_type=='cuda']
  - url: https://github.com/onnx/onnx/archive/850a81b0b77786bf99ea90580242b084f86a6235.zip
    sha256: fe4e792485e88b7ba745a78ddd8ee16346078e1991845ac95f01962a165d64bd
    folder: onnx
  - url: https://gitlab.com/libeigen/eigen/-/archive/d10b27fe37736d2944630ecd7557cefa95cf87c9/eigen-d10b27fe37736d2944630ecd7557cefa95cf87c9.tar.gz
    sha256: a3c10a8c14f55e9f09f98b0a0ac6874c21bda91f65b7469d9b1f6925990e867b
    folder: eigen
  - url: https://github.com/NVlabs/cub/archive/c3cceac115c072fb63df1836ff46d8c60d9eb304.zip
    sha256: 8894c68d7549681591c34078dcd40cf34459b6c7d33407f07e2145d2adb683ee 
    folder: cub
  - url: https://github.com/nlohmann/json/archive/db78ac1d7716f56fc9f1b030b715f872f93964e4.zip
    sha256: 520907d368d32830771d1ed606821aa8a7501cbf7929b433c5ac0065027fa6e4
    folder: json
  - url: https://github.com/pytorch/cpuinfo/archive/5916273f79a21551890fd3d56fc5375a78d1598d.zip
    sha256: 2a160c527d3c58085ce260f34f9e2b161adc009b34186a2baf24e74376e89e6d 
    folder: cpuinfo

build:
  number: 1
  string: h{{ PKG_HASH }}_{{ build_type }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }}   #[build_type == 'cpu']
  string: h{{ PKG_HASH }}_{{ build_type }}{{ cudatoolkit | replace(".*", "") }}_py{{ python | replace(".", "") }}_pb{{ protobuf | replace(".*", "")}}_{{ PKG_BUILDNUM }} #[build_type == 'cuda']
  script_env:
    - CUDA_HOME      #[build_type == 'cuda']

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - cmake {{ cmake }}
    - libprotobuf {{ protobuf }}
    - boost_mp11 {{ boost_mp11 }}
    - gmock {{ gmock }}
    - gtest {{ gmock }}
    - optional-lite {{ optional_lite }}
    - nlohmann_json {{ nlohmann_json }}
    - safeint {{ safeint }}
    - libdate {{ libdate }}
    {% if build_type == 'cuda' %}
    - cudatoolkit {{ cudatoolkit }}
    - cudnn {{ cudnn }}
    {% endif %}

  host:
    - python {{ python }}
    - pip
    - wheel
    - flake8
    - flatbuffers {{ flatbuffers }}
    - python-flatbuffers {{ flatbuffers }}
    - re2
    - nsync
    - libprotobuf {{ protobuf }}
    # We need to statically link protobuf until we link against a system libonnx
    # See: https://github.com/conda-forge/onnxruntime-feedstock/issues/5
    - libprotobuf-static {{ protobuf }}
    - numpy {{ numpy }}
    - pybind11
    - ninja {{ ninja }}

  run:
    - python {{ python }}
    - numpy {{ numpy }}
    - protobuf {{ protobuf }}
    - python-flatbuffers {{ flatbuffers }}
    {% if build_type == 'cuda' %}
    - cudatoolkit {{ cudatoolkit }}
    - cudnn {{ cudnn }}
    {% endif %}

test:
  imports:
    - onnxruntime
  commands:
    - pip check
  requires:
    - pip

about:
  home: http://onnxruntime.ai/
  summary: cross-platform, high performance ML inferencing and training accelerator
  license: MIT
  license_file:
    - LICENSE
    - cmake/external/onnx/LICENSE
  description: |
    ONNX Runtime is a cross-platform inference and training machine-learning accelerator.
  dev_url: https://github.com/microsoft/onnxruntime/
  doc_url: https://github.com/microsoft/onnxruntime/tree/master/docs

extra:
  recipe-maintainers:
    - open-ce/open-ce-dev-team
